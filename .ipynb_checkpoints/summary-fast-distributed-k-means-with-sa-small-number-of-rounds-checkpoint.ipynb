{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7086e694-db7e-4cd0-b015-93aa55e30856",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances_argmin_min"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10145f08-e011-467d-9655-a449cdf26042",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "# Summary of _Fast Distributed k-Means with a Small Number of Rounds_ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18680a3c-9252-427f-bac2-385cf35fa731",
   "metadata": {},
   "source": [
    "Source: https://arxiv.org/abs/2201.13217 \\\n",
    "Authors: Tom Hess, Ron Visbord, Sivan Sabato"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a503e7-fb9f-40b2-8b4f-c5c182f0325c",
   "metadata": {},
   "source": [
    "## 1 Summary of paper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9bc2fd-0c61-4ceb-baee-a2bb1dc2d096",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    " ### 1.1 Introduction  \n",
    "When working with very large datasets, we often need to split the data across many computers to process it faster. This is called distributed computing. A common task in machine learning is clustering, where we group similar items together. One popular method for clustering is called k-means, which tries to group data into **k clusters** based on similarity. However, applying k-means to distributed data comes with challenges, especially the high communication cost when computers need to share information multiple times.  \n",
    "\n",
    "To address this, the paper introduces a new method called **SOCCER**. This algorithm allows computers to cluster data while needing only a few communication steps, usually between 1 and 4. Compared to other popular methods like **k-means\\|\\|**, SOCCER works faster, uses fewer resources, and still achieves better results in most cases.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23f4f8d-ea14-408b-a3cc-9a022c4a5fa2",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "### 1.2 Why Distributed Clustering Is Hard  \n",
    "Imagine you want to divide 10 million pictures into groups of similar images. Storing all pictures in one computer might not be possible due to limited memory. So, you split the pictures across several computers. But now, for these computers to work together, they need to communicate and share results. Each time they communicate is called a **round**, and more rounds mean more time and cost.  \n",
    "\n",
    "Many current methods, like **k-means\\|\\|**, need many rounds of communication or use fixed rules for how long they run, which can waste time. SOCCER improves this by deciding automatically when it has done enough work and can stop, saving both time and communication effort."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bc3b3b-0417-4fc6-b09b-cb94f75520c5",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "### 1.3 How SOCCER Works  \n",
    "SOCCER simplifies the clustering process by using a coordinator computer to guide the other machines. Each machine sends only a small sample of its data to the coordinator, which finds patterns and tells the machines which data to keep or remove. This process repeats until the data size becomes small enough for the coordinator to handle on its own.  \n",
    "\n",
    "At each step, the coordinator uses a special calculation to estimate whether it has enough information to stop. If it does, the algorithm ends early, often after just 1 or 2 rounds. This makes SOCCER much faster than alternatives like k-means||, which keeps running without such checks.  \n",
    "\n",
    "Here’s how the process works step-by-step:\n",
    "\n",
    "1. **Sampling**: Each machine randomly selects a small fraction of its data and sends it to the coordinator. \\\n",
    "   (Relevant Code: Sampling is done using Machine.sample_points, which randomly selects a fraction of the machine's data.)\n",
    "3. **Clustering**: The coordinator clusters this small sample and estimates how well it represents the overall dataset. \\\n",
    "   (Relevant Code: Clustering is performed in the Coordinator.cluster_points method, which uses scikit-learn's KMeans.)\n",
    "5. **Data Removal**: Based on the results, the machines remove data points that are no longer needed for clustering. \\\n",
    "   (Relevant Code: Data removal is handled by Machine.remove_points, which filters data based on a distance threshold calculated by Coordinator.calculate_threshold.)\n",
    "7. **Stopping**: The algorithm stops when the dataset is reduced enough for the coordinator to finish the clustering alone. \\\n",
    "   (Relevant Code: Stopping is controlled by the condition if remaining_points <= total_points * capacity_ratio in soccer_algorithm.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a1f735-fecb-4c07-ac18-e35b165deed6",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "### 1.4 Comparing SOCCER with k-means\\|\\|  \n",
    "SOCCER and k-means|| both try to solve the same problem, but they work very differently. Here’s a comparison:  \n",
    "\n",
    "| **Feature**               | **SOCCER**                     | **k-means\\|\\|**                 |\n",
    "|---------------------------|--------------------------------|-------------------------------|\n",
    "| Communication rounds       | 1–4 (usually stops early)     | Fixed number, often too many |\n",
    "| Clustering cost (quality)  | Lower (better groups)         | Higher (worse groups)        |\n",
    "| Machine computation time   | Much faster                   | Slower                       |\n",
    "| Adaptability               | Stops automatically           | Requires manual adjustment   |\n",
    "\n",
    "For example, on a dataset with 10 million data points, SOCCER could complete clustering in just one round, while k-means|| would need 5 rounds and still produce worse results.\n",
    "\n",
    "(**Relevant Code**: This comparison is implemented in the `compare_algorithms` function, which measures the rounds and costs for both `soccer_algorithm` and `kmeans_parallel`.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e548b7c1-0837-4fbb-99ab-4e8f06283e4c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "### 1.5 A Simple Example  \n",
    "Imagine sorting marbles of different colors into separate bins. You want to do this in a group, where each person gets a bag of marbles to sort. One person, the coordinator, collects a small sample from everyone and decides how to split the marbles. They then send back instructions, like \"Put all red marbles in bin 1.\" This repeats until everyone’s bags are sorted. SOCCER is like having a coordinator who knows when they have seen enough marbles to stop sorting early, saving time and effort. \n",
    "\n",
    "(**Relevant Code**: Sampling, clustering, and removal steps in `soccer_algorithm` reflect this analogy. Machines send samples via `Machine.sample_points`, and the coordinator clusters and provides instructions via `Coordinator.cluster_points` and `Coordinator.calculate_threshold`.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f01a082-ad6f-4d39-8b08-620998e0cf33",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "### 1.6 Results and Insights  \n",
    "SOCCER was tested on different datasets, including both synthetic (computer-generated) and real-world data. These datasets ranged from 2 million to 10 million points and had different levels of complexity. Across all tests, SOCCER consistently outperformed k-means\\|\\| in terms of speed and accuracy.  \n",
    "\n",
    "Here’s an example of the results:  \n",
    "\n",
    "| **Dataset**      | **Number of Points** | **SOCCER Rounds** | **k-means\\|\\| Rounds** | **SOCCER Cost** | **k-means\\|\\| Cost** |\n",
    "|------------------|----------------------|-------------------|----------------------|----------------|-------------------|\n",
    "| Gaussian Mixture | 10 million           | 1                 | 5                    | 150            | 164               |\n",
    "| Higgs Boson      | 11 million           | 2                 | 3                    | 122 million    | 137 million       |\n",
    "\n",
    "These results show that SOCCER not only stops earlier but also creates better clusters with lower cost.  \n",
    "\n",
    "(**Relevant Code**: This is demonstrated in the `compare_algorithms` function, where the clustering cost and rounds are measured for both algorithms on synthetic datasets.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45df8f5e-607a-49cf-b5ad-91db212db86f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "### 1.7 Why SOCCER Is Better  \n",
    "SOCCER has two key advantages. First, it uses the coordinator’s memory smartly, which allows it to process data in smaller pieces and reduces the total communication. Second, it adjusts to the dataset’s structure. If the data is easy to cluster, SOCCER finishes in just one round. If it’s harder, it runs more rounds but stops as soon as it’s done enough work.  \n",
    "\n",
    "For example, when working with datasets made from high-dimensional Gaussian distributions, SOCCER could often find the right clusters in just one round. In contrast, k-means|| required multiple rounds and still gave poorer results.  \n",
    "\n",
    "(**Relevant Code**: The Gaussian mixture data generation in `generate_data` demonstrates this scenario, with the results displayed in `compare_algorithms`.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19153bc-ea6a-4989-aa64-368a9609c83b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "### 1.8 Conclusion  \n",
    "SOCCER makes clustering large datasets much faster and more efficient. It reduces the need for communication and computing time, making it ideal for real-world applications where speed and resources are limited. Beginners can think of it as a smart, self-stopping organizer that groups data faster than other methods.  \n",
    "\n",
    "In the future, SOCCER could be adapted to handle even more complex scenarios, like dealing with noisy data or ensuring privacy. For now, it is already a big step forward for distributed clustering.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a285065-6787-43c9-8f9d-ce1bb3861f3b",
   "metadata": {},
   "source": [
    "## 2 Proof of concept"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2c977d-af49-4465-a480-f9de7e169168",
   "metadata": {},
   "source": [
    "The authors of the paper have provided a github repository with their code, however, this summary is going to provide new code from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f17ec3-5d16-4ce3-b04a-afbb0df5c64a",
   "metadata": {},
   "source": [
    "### 2.1 Data generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9cb7d4-4449-487e-a0d3-57900e4aa0d8",
   "metadata": {},
   "source": [
    "This function generates synthetic data for testing purposes. The data is created as a mixture of Gaussian distributions, where each distribution represents a cluster. This allows us to simulate clustering tasks on a synthetic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53844f10-8ae3-4af1-9be8-24912e2ca897",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(num_points=100000, num_clusters=5, dim=2, std=1.0):\n",
    "    centers = np.random.uniform(-10, 10, size=(num_clusters, dim))\n",
    "    data = []\n",
    "    for center in centers:\n",
    "        points = np.random.normal(loc=center, scale=std, size=(num_points // num_clusters, dim))\n",
    "        data.append(points)\n",
    "    return np.vstack(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49daf98a-0784-42c1-88f3-dfda986393fc",
   "metadata": {},
   "source": [
    "### 2.2 Machine class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4018567b-4197-4bb8-9b6e-78dab3170544",
   "metadata": {},
   "source": [
    "This class represents a machine in the distributed system. Each machine holds a subset of the data and is responsible for sampling and removing points based on the clustering centers sent by the coordinator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2d44c55-bdf5-440b-ba32-aa8d6e5bde47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distributed machines holding parts of the dataset\n",
    "class Machine:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def sample_points(self, sample_ratio):\n",
    "        sample_size = int(len(self.data) * sample_ratio)\n",
    "        indices = np.random.choice(len(self.data), sample_size, replace=False)\n",
    "        return self.data[indices]\n",
    "\n",
    "    def remove_points(self, centers, threshold):\n",
    "        distances = np.min([np.linalg.norm(self.data - center, axis=1) for center in centers], axis=0)\n",
    "        self.data = self.data[distances > threshold]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01441149-5c20-485b-9d2d-5b7dcdc30409",
   "metadata": {},
   "source": [
    "### 2.3 Coordinator class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1974745e-ba65-4843-9672-7ca193388494",
   "metadata": {},
   "source": [
    "The coordinator is the central entity responsible for clustering data from all machines. It performs the actual k-means clustering and calculates a threshold to decide which data points to keep or remove from the machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e984dd6-b416-4e29-9ec4-19d36b69e4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Coordinator:\n",
    "    def __init__(self, num_clusters, capacity_ratio=0.01):\n",
    "        self.num_clusters = num_clusters\n",
    "        self.capacity_ratio = capacity_ratio\n",
    "        self.centers = []\n",
    "\n",
    "    def cluster_points(self, points):\n",
    "        kmeans = KMeans(n_clusters=self.num_clusters, random_state=0)\n",
    "        kmeans.fit(points)\n",
    "        return kmeans.cluster_centers_\n",
    "\n",
    "    def calculate_threshold(self, points, centers):\n",
    "        distances = np.min([np.linalg.norm(points - center, axis=1) for center in centers], axis=0)\n",
    "        return np.percentile(distances, 95)  # 95th percentile as a heuristic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d51aaf-7ea1-4c1e-a52c-388e769d15bc",
   "metadata": {},
   "source": [
    "### 2.4 Soccer algoritm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c962ae5-acef-4019-949b-5fa323d8fd5f",
   "metadata": {},
   "source": [
    "The SOCCER algorithm is implemented in this function. It coordinates the distributed clustering process, with machines sending samples to the coordinator, who clusters them and removes points from each machine’s dataset based on the clustering results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5f93c90-ee6a-41ba-9301-2dce5c8ff10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def soccer_algorithm(data, num_clusters, num_machines, capacity_ratio=0.01, sample_ratio=0.1, max_rounds=10):\n",
    "    np.random.shuffle(data)\n",
    "    machine_data = np.array_split(data, num_machines)\n",
    "    machines = [Machine(data) for data in machine_data]\n",
    "    \n",
    "    coordinator = Coordinator(num_clusters, capacity_ratio)\n",
    "    total_points = len(data)\n",
    "    round_count = 0\n",
    "\n",
    "    while round_count < max_rounds:\n",
    "        round_count += 1\n",
    "\n",
    "        # Step 1: Sampling\n",
    "        sampled_points = np.vstack([machine.sample_points(sample_ratio) for machine in machines])\n",
    "\n",
    "        # Step 2: Clustering sampled points\n",
    "        if len(sampled_points) > total_points * capacity_ratio:\n",
    "            sampled_points = sampled_points[:int(total_points * capacity_ratio)]\n",
    "        new_centers = coordinator.cluster_points(sampled_points)\n",
    "        coordinator.centers.extend(new_centers)\n",
    "\n",
    "        # Step 3: Remove points\n",
    "        threshold = coordinator.calculate_threshold(sampled_points, new_centers)\n",
    "        for machine in machines:\n",
    "            machine.remove_points(new_centers, threshold)\n",
    "\n",
    "        # Check stopping condition\n",
    "        remaining_points = sum(len(machine.data) for machine in machines)\n",
    "        if remaining_points <= total_points * capacity_ratio:\n",
    "            break\n",
    "\n",
    "    # Final clustering\n",
    "    remaining_data = np.vstack([machine.data for machine in machines])\n",
    "    final_centers = coordinator.cluster_points(remaining_data)\n",
    "    return final_centers, round_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43f4c7e-3207-4cd1-b9a5-084eff19a546",
   "metadata": {},
   "source": [
    "### 2.5 k-means|| algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f74e49-0f08-4e60-b0f5-fe091f76ee6b",
   "metadata": {},
   "source": [
    "This function simulates the k-means|| algorithm, a popular method for distributed k-means clustering. It runs for a fixed number of rounds, as described in the article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54ce0faa-b0dc-429b-9583-fc13b0712592",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_parallel(data, num_clusters, num_rounds=5):\n",
    "    np.random.shuffle(data)\n",
    "    centers = data[np.random.choice(len(data), num_clusters, replace=False)]\n",
    "    for _ in range(num_rounds):\n",
    "        distances = np.min(np.linalg.norm(data[:, None] - centers, axis=2), axis=1)\n",
    "        probabilities = distances / np.sum(distances)\n",
    "        new_centers = data[np.random.choice(len(data), num_clusters, p=probabilities, replace=False)]\n",
    "        centers = np.vstack((centers, new_centers))\n",
    "        if len(centers) > num_clusters:\n",
    "            labels, _ = pairwise_distances_argmin_min(data, centers)\n",
    "            cluster_centers = []\n",
    "            for i in range(num_clusters):\n",
    "                cluster_centers.append(data[labels == i].mean(axis=0))\n",
    "            centers = np.array(cluster_centers)\n",
    "    return centers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a65686-3818-4887-b3ae-b5932a39ee51",
   "metadata": {},
   "source": [
    "### 2.6 Comparison function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb068e88-e99e-4b48-9e6f-e14f37d87de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_algorithms():\n",
    "    data = generate_data(num_points=10000, num_clusters=5, dim=2, std=0.5)\n",
    "\n",
    "    # Run SOCCER\n",
    "    soccer_centers, soccer_rounds = soccer_algorithm(data, num_clusters=5, num_machines=10)\n",
    "    soccer_labels, soccer_costs = pairwise_distances_argmin_min(data, soccer_centers)\n",
    "    soccer_cost = np.sum(soccer_costs**2)\n",
    "\n",
    "    # Run k-means||\n",
    "    kmeans_centers = kmeans_parallel(data, num_clusters=5, num_rounds=5)\n",
    "    kmeans_labels, kmeans_costs = pairwise_distances_argmin_min(data, kmeans_centers)\n",
    "    kmeans_cost = np.sum(kmeans_costs**2)\n",
    "\n",
    "    # Print Results\n",
    "    print(\"SOCCER Results:\")\n",
    "    print(f\"Rounds: {soccer_rounds}\")\n",
    "    print(f\"Clustering Cost: {soccer_cost:.2f}\\n\")\n",
    "\n",
    "    print(\"k-means|| Results:\")\n",
    "    print(f\"Rounds: 5 (fixed)\")\n",
    "    print(f\"Clustering Cost: {kmeans_cost:.2f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f746734d-528e-426b-ac2b-8bef25f64dd4",
   "metadata": {},
   "source": [
    "### 2.7 Perform the comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73262acb-58dd-41e7-bd04-837c63d330e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOCCER Results:\n",
      "Rounds: 2\n",
      "Clustering Cost: 184589.68\n",
      "\n",
      "k-means|| Results:\n",
      "Rounds: 5 (fixed)\n",
      "Clustering Cost: 327449.02\n",
      "\n"
     ]
    }
   ],
   "source": [
    "compare_algorithms()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "scenes_data": {
   "active_scene": "Default Scene",
   "init_scene": "",
   "scenes": [
    "Default Scene"
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
